{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPGFeru0D2CASA4rc82jvsZ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["------This Jupyter notebook is authored by J. Antonio Sidaoui, jas2545@columbia.edu------"],"metadata":{"id":"L2eHT8lI99A9"}},{"cell_type":"code","source":["import statsmodels.api as sm\n","import numpy as np\n","\n","def fit_multivariate_regression(x, y):\n","  \"\"\"\n","  Fits multiple linear regression models, one for each column of y on x.\n","\n","  Parameters:\n","  - x: Independent variables (n x p matrix)\n","  - y: Dependent variables (n x q matrix)\n","\n","  Returns:\n","  - res: List of fitted model objects\n","  \"\"\"\n","\n","  res = []\n","  for i in range(y.shape[1]):\n","    # Add a constant to the independent variables\n","    #x = sm.add_constant(x)\n","\n","    # Create and fit the linear regression model for the i-th column of y\n","    mod = sm.OLS(y[:, i], x)\n","    res_i = mod.fit()\n","\n","    # Append the fitted model to the list\n","    res.append(res_i)\n","  return res\n","\n","def predict_multivariate_regression(fitted_eq, x):\n","  \"\"\"\n","  Predicts the entire vector y given a new point x\n","  from the fitted equations.\n","\n","  Parameters:\n","  - fitted_eq: List of fitted model objects\n","  - x: New data point (1 x p matrix)\n","\n","  Returns:\n","  - y_pred: Predicted y vector (1 x q matrix)\n","  \"\"\"\n","\n","  #x = sm.add_constant(x)\n","  y_pred = np.zeros(len(fitted_eq))\n","  for i, model in enumerate(fitted_eq):\n","    y_pred[i] = model.predict(x)[0]\n","  return y_pred"],"metadata":{"id":"kX-iCEfstoaA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Dynamic PCA Historical Backtest"],"metadata":{"id":"VKViahcfuA6f"}},{"cell_type":"code","source":["def pca_kalman_filter(x_data, W, F, Q, R_x, z0, P0):\n","    T, n = x_data.shape\n","    k = W.shape[1]\n","\n","    z_est = np.zeros((T, k))\n","    P_est = np.zeros((T, k, k))\n","\n","    z_prev = z0\n","    P_prev = P0\n","\n","    for t in range(T):\n","        # Prediction Step\n","        z_pred = F @ z_prev\n","        P_pred = F @ P_prev @ F.T + Q\n","\n","        # Update Step\n","        y_t = x_data[t]\n","        K = P_pred @ W.T @ np.linalg.inv(W @ P_pred @ W.T + R_x)\n","        z_post = z_pred + K @ (y_t - W @ z_pred)\n","        P_post = P_pred - K @ W @ P_pred\n","\n","        # Store estimates\n","        z_est[t] = z_post\n","        P_est[t] = P_post\n","\n","        # Update for next iteration\n","        z_prev = z_post\n","        P_prev = P_post\n","\n","    return z_est, P_est"],"metadata":{"id":"co3s6Q76tock"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def historical_backtest_dynamic_pca(x, y, scenario_vars, crisis_dates, dynamic_pca_dim, start_row):\n","    \"\"\"\n","    Historical Backtest with Kalman filter re-fitted every refit_interval years (input in months).\n","    Scenario stress variables are the FED stress test variables.\n","\n","    Parameters:\n","    - x: Input data (T x features)\n","    - y: Response data (T x features)\n","    - scenario_vars: Indices of stress scenario variables\n","    - crisis_dates: List of dates indicating crisis periods\n","    - DMdim: Dimension of the diffusion map\n","    - start_row: Starting row for the out-of-sample prediction\n","\n","    Returns:\n","    - abs_error_pca: Absolute errors for Dynamic PCA predictions\n","    - pca_val: Dynamic pCA portfolio values\n","    - true_val: Actual portfolio values\n","    \"\"\"\n","\n","    T = crisis_dates[-1] - start_row  # Predict out-of-sample up to the end of the crisis\n","    s = crisis_dates[0] - start_row  # Train on all past dates up to the first crisis date\n","    K = 10000  # Monte Carlo samples\n","    refit_interval = 50  # refit_interval years of monthly data (in months)\n","\n","    abs_error_pca = np.zeros(T - s)\n","    pca_val = np.zeros(T - s)\n","    true_val = np.zeros(T - s)\n","\n","    iter = 0\n","    z_est_full = np.zeros((T, dynamic_pca_dim))  # Store full z_hat for all periods\n","\n","    for refit_start in range(0, T, refit_interval):\n","        refit_end = min(refit_start + refit_interval + s, T)\n","\n","        # ===== Re-fit the Kalman filter every refit_interval years =====\n","\n","        # PCA\n","        scaler=preprocessing.StandardScaler(with_std=False).fit(x[refit_start:refit_end])\n","        factors_centered=scaler.transform(x[refit_start:refit_end])\n","        pca = PCA(n_components=dynamic_pca_dim)\n","        z_data = pca.fit_transform(factors_centered)  # PC embeddings\n","        W_pca = pca.components_.T  # PCA loading matrix\n","        # Fit a VAR(1) model to the PC embeddings\n","        model = VAR(z_data)\n","        results = model.fit(1)\n","        F_pca = results.coefs[0]  # State transition matrix (k x k)\n","        Q_pca = np.cov(results.resid.T)  # Process noise covariance (k x k)\n","        # Initialize parameters\n","        R_x_pca = np.diag(np.var(x[refit_start:refit_end], axis=0))\n","        z0 = np.zeros(W_pca.shape[1])  # Initial state\n","        P0_pca = np.eye(W_pca.shape[1])  # Initial state covariance\n","        # Run the Kalman filter\n","        z_est, P_est = pca_kalman_filter(x[refit_start:refit_end], W_pca, F_pca, Q_pca, R_x_pca, z0, P0_pca)\n","\n","        z_est_full[refit_start:refit_end] = z_est\n","\n","        # ===== Backtest for the next refit_interval years =====\n","\n","        for t in range(max(s, refit_start + s), refit_end):\n","            # PCA\n","            z_est_t=z_est_full[t-s:t] # Use precomputed latent state estimates\n","            fitted_eq=fit_multivariate_regression(x[t-s:t], y[t-s:t]) # Fit multivariate regression\n","            portfolio_values_pca=np.zeros(K)\n","\n","            for k in range(K):\n","              z_est_t1=conditional_sample_H(F_pca, Q_pca, W_pca, z_est_t[-1], scenario_vars, np.array([x[t-s:t+1][-1][i] for i in scenario_vars])) # Sample z_t+1|scenario\n","              x_t1_pca=W_pca @ z_est_t1 # lift predicted PC embedding vector to original factor space\n","              y_t1_pca=predict_multivariate_regression(fitted_eq, x_t1_pca) # predict returns given the estimated factor\n","              weights=1/y_t1_pca.shape[0]*np.ones(y_t1_pca.shape[0]) # construct portfolio with 1/N rule\n","              portfolio_values_pca[k]=np.dot(weights, y_t1_pca) # find portfolio value\n","\n","            val_pca=np.mean(portfolio_values_pca) # average over Monte Carlo samples\n","            pca_val[iter]=val_pca\n","\n","            # Actual value\n","            y_t1_actual = y[t-s:t+1][-1]\n","            weights = 1 / y_t1_actual.shape[0] * np.ones(y_t1_actual.shape[0])\n","            val_actual = np.dot(weights, y_t1_actual)\n","            true_val[iter] = val_actual\n","\n","            # Absolute error Dynamic PCA\n","            abs_error_pca[iter] = np.abs(val_actual - val_pca)\n","\n","            print(f\"Iteration {iter}/{T-s}\")\n","            iter += 1\n","\n","    return abs_error_pca, pca_val, true_val"],"metadata":{"id":"qTpUmbxGtofp"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# SSA Historical Backtest"],"metadata":{"id":"K360sEr17oKq"}},{"cell_type":"code","source":["def historical_backtest_ssa(x, y, scenario_vars, crisis_dates, start_row):\n","    \"\"\"\n","    Historical Backtest with Kalman filter re-fitted every 3 years (36 months).\n","    Scenario stress variables are the FED stress test variables.\n","\n","    Parameters:\n","    - x: Input data (T x features)\n","    - y: Response data (T x features)\n","    - scenario_vars: Indices of stress scenario variables\n","    - crisis_dates: List of dates indicating crisis periods\n","    - DMdim: Dimension of the diffusion map\n","    - start_row: Starting row for the out-of-sample prediction\n","\n","    Returns:\n","    - abs_error_dmk: Absolute errors for SSA predictions\n","    - ssa_val: SSA portfolio values\n","    - true_val: Actual portfolio values\n","    \"\"\"\n","\n","    T = crisis_dates[-1] - start_row # Predict out-of-sample up to the end of the crisis\n","    s = crisis_dates[0] - start_row  # Train on all past dates up to the first crisis date\n","\n","    abs_error_ssa = np.zeros(T - s)\n","    ssa_val = np.zeros(T - s)\n","    true_val = np.zeros(T - s)\n","    iter=0\n","\n","    for t in range(s, T):\n","\n","      # SSA\n","      x_t1_ssa=x[t-s:t][-1] # set the unstressed factors equal to previous value (change is set to zero)\n","      for i in scenario_vars:\n","        x_t1_ssa[i]=x[t-s:t+1][-1][i] # set to actual scenario in t+1\n","\n","      fitted_eq=fit_multivariate_regression(x[t-s:t], y[t-s:t])\n","\n","      y_t1_ssa=predict_multivariate_regression(fitted_eq, x_t1_ssa) # predict returns given the x_t1\n","      weights=1/y_t1_ssa.shape[0]*np.ones(y_t1_ssa.shape[0]) # construct portfolio with 1/N rule (add code for value weighted as well)\n","      val_ssa=np.dot(weights, y_t1_ssa)\n","      ssa_val[iter]=val_ssa\n","\n","      # Actual value\n","      y_t1_actual = y[t-s:t+1][-1]\n","      weights = 1 / y_t1_actual.shape[0] * np.ones(y_t1_actual.shape[0])\n","      val_actual = np.dot(weights, y_t1_actual)\n","      true_val[iter] = val_actual\n","\n","      # Absolute error SSA\n","      abs_error_ssa[iter] = np.abs(val_actual - val_ssa)\n","\n","      print(f\"Iteration {iter}/{T-s}\")\n","      iter += 1\n","\n","    return abs_error_ssa, ssa_val, true_val"],"metadata":{"id":"SJzqeRHktoh-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Static PCA Historical Backtest"],"metadata":{"id":"mRoxqlDw8b2P"}},{"cell_type":"code","source":["def historical_backtest_with_static_pca(x, y, scenario_vars, PCDims, crisis_dates, start_row):\n","    \"\"\"\n","    Perform historical backtest with dynamic PCA and static PCA projections.\n","\n","    Parameters:\n","    - x: Factor matrix (T x N)\n","    - y: Return matrix (T x M)\n","    - scenario_vars: Indices of stressed scenario variables\n","    - crisis_dates: List of dates indicating crisis periods\n","    - DMdim: Dimensionality for diffusion maps\n","    - PCDims: List of PCA dimensions to evaluate (e.g., [5, 10, 30, 50, \"all\"])\n","\n","    Returns:\n","    - Dictionary containing results for static PCA with different dimensions\n","    \"\"\"\n","\n","    T = crisis_dates[-1] - start_row  # Predict out-of-sample up to the end of the crisis\n","    s = crisis_dates[0] - start_row  # Train on all past dates up to the first crisis date\n","    K = 10000  # Monte Carlo samples\n","    abs_error_static_pca_results = {}\n","    static_pca_val_results = {}\n","\n","    iter = 0\n","    for t in range(s, T):\n","        # Scale the data (center only)\n","        x_diff = np.diff(x[t-s:t], axis=0)  # Shape: (s-1, N)\n","        scaler = preprocessing.StandardScaler(with_std=False).fit(x_diff)#x[t-s:t])\n","        factors_centered = scaler.transform(x_diff)#x[t-s:t])\n","\n","        # Fit multivariate regression\n","        fitted_eq = fit_multivariate_regression(x[t-s:t], y[t-s:t])\n","\n","        # Static PCA for each specified dimensionality\n","        for pca_dim in PCDims:\n","            # Adjust PCA dimensions\n","            if pca_dim == \"all\":\n","              pca_dim = x.shape[1]  # Use all components\n","\n","            # Perform PCA\n","            pca = PCA(n_components=pca_dim)\n","            pca.fit(factors_centered)\n","            W = pca.components_.T  # PCA loading matrix\n","\n","            x_t1_ssa=x[t-s:t][-1] # set the unstressed factors equal to previous value (change is set to zero)\n","            for i in scenario_vars:\n","              x_t1_ssa[i]=x[t-s:t+1][-1][i] # set to actual scenario in t+1\n","\n","            # Static PCA stress test\n","            delta_x=x_t1_ssa-x[t-s:t][-1] # change/perturbation vector\n","            delta_x_centered = scaler.transform(delta_x.reshape(1, -1)).flatten()  # Center perturbation vector\n","            proj_delta = W @ (W.T @ delta_x_centered)  # Project stress onto PCA space\n","            x_t1_static_pca = x[t-s:t][-1] + proj_delta + scaler.mean_  # Apply perturbation\n","            y_t1_static_pca = predict_multivariate_regression(fitted_eq, x_t1_static_pca)  # Predict returns\n","\n","            # Construct portfolio using equal weights\n","            weights = 1 / y_t1_static_pca.shape[0] * np.ones(y_t1_static_pca.shape[0])\n","            val_static_pca = np.dot(weights, y_t1_static_pca)\n","\n","            # Save results\n","            if pca_dim not in static_pca_val_results:\n","                static_pca_val_results[pca_dim] = np.zeros(T - s)\n","                abs_error_static_pca_results[pca_dim] = np.zeros(T - s)\n","\n","            static_pca_val_results[pca_dim][iter] = val_static_pca\n","\n","        # Actual returns\n","        y_t1_actual = y[t-s:t+1][-1]\n","        weights_actual = 1 / y_t1_actual.shape[0] * np.ones(y_t1_actual.shape[0])\n","        val_actual = np.dot(weights_actual, y_t1_actual)\n","\n","        # Absolute error for static PCA\n","        for pca_dim in PCDims:\n","            dim = pca_dim if pca_dim != \"all\" else x.shape[1]\n","            abs_error_static_pca_results[dim][iter] = np.abs(val_actual - static_pca_val_results[dim][iter])\n","\n","        print(iter)\n","        iter += 1\n","\n","    return abs_error_static_pca_results, static_pca_val_results"],"metadata":{"id":"5D4dMlkk8anU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# JDKF Historical Backtest"],"metadata":{"id":"lccjVqbu8vK7"}},{"cell_type":"code","source":["def historical_backtest_jdkf(x, y, scenario_vars, crisis_dates, DMdim, start_row):\n","    \"\"\"\n","    Historical Backtest with Kalman filter re-fitted every refit_interval years (in months).\n","    Scenario stress variables are the FED stress test variables.\n","\n","    Parameters:\n","    - x: Input data (T x features)\n","    - y: Response data (T x features)\n","    - scenario_vars: Indices of stress scenario variables\n","    - crisis_dates: List of dates indicating crisis periods\n","    - DMdim: Dimension of the diffusion map\n","    - start_row: Starting row for the out-of-sample prediction\n","\n","    Returns:\n","    - abs_error_dmk: Absolute errors for JDKF predictions\n","    - dmk_val: JDKF portfolio values\n","    - true_val: Actual portfolio values\n","    \"\"\"\n","\n","    T = crisis_dates[-1] - start_row # Predict out-of-sample up to the end of the crisis\n","    s = crisis_dates[0] - start_row  # Train on all past dates up to the first crisis date\n","    K = 10000  # Monte Carlo samples\n","    refit_interval = 50  # refit_interval years of monthly data (in months)\n","\n","    psi_dim = DMdim\n","    abs_error_dmk = np.zeros(T - s)\n","    dmk_val = np.zeros(T - s)\n","    true_val = np.zeros(T - s)\n","\n","    iter = 0\n","    psi_hat_full = np.zeros((T, psi_dim))  # Store full psi_hat for all periods\n","\n","    for refit_start in range(0, T, refit_interval):\n","        refit_end = min(refit_start + refit_interval + s, T)\n","\n","        # ===== Re-fit the Kalman filter every refit_interval years =====\n","        scaler = preprocessing.StandardScaler(with_std=False).fit(x[refit_start:refit_end])\n","        factors_centered = scaler.transform(x[refit_start:refit_end])\n","        D = compute_distances(factors_centered)\n","        W = compute_affinity_matrix(D, 'gaussian', sigma=np.median(D))\n","        diff_vec, diff_eig = diff_map_info(W)\n","\n","        lambda_k = -(2 / (np.median(D) ** 2)) * np.log(diff_eig[:psi_dim])\n","        F = np.eye(psi_dim) + np.diag(-lambda_k)\n","        H_x = x[refit_start:refit_end].T @ diff_vec[:, :psi_dim]\n","        Q = np.diag(np.var(diff_vec[:, :psi_dim] @ np.diag(diff_eig[:psi_dim]), axis=0))\n","        R_x = np.diag(np.var(x[refit_start:refit_end], axis=0))\n","        R_xy=((x[refit_start:refit_end]-x[refit_start:refit_end].mean(axis=0)).T @ (y[refit_start:refit_end]-y[refit_start:refit_end].mean(axis=0)))/y[refit_start:refit_end].shape[0]\n","        x0 = diff_vec[:, :psi_dim][0]\n","        P0 = np.eye(psi_dim)\n","\n","        # Run the Kalman filter for the refit_inverval-year window\n","        A_opt, R_z_opt, R_y_opt, R_yz_opt, x_smooth, psi_hat, log_likelihoods = em_kalman_filter(x[refit_start:refit_end], y[refit_start:refit_end], F, H_x, Q, x0, P0)\n","\n","        # Store psi_hat in the full array\n","        psi_hat_full[refit_start:refit_end] = psi_hat\n","\n","        # ===== Backtest for the next refit_interval years =====\n","        for t in range(max(s, refit_start + s), refit_end):\n","            psi_hat_t = psi_hat_full[t-s:t]  # Use precomputed latent state estimates\n","\n","            portfolio_values_dmk = np.zeros(K)\n","\n","            for k in range(K):\n","                # Sample psi_t+1|scenario using the last psi_hat from the training window\n","                psi_t1 = conditional_sample_H(F, Q, H_x, psi_hat_t[-1], scenario_vars, np.array([x[t-s:t+1][-1][i] for i in scenario_vars]))\n","\n","                # Predict returns given the estimated factor vector\n","                y_t1 = A_opt @ H_x @ psi_t1\n","\n","                # Construct portfolio with 1/N rule\n","                weights = 1 / y_t1.shape[0] * np.ones(y_t1.shape[0])\n","                portfolio_values_dmk[k] = np.dot(weights, y_t1)\n","\n","            val_dmk = np.mean(portfolio_values_dmk)  # Average over Monte Carlo samples\n","            dmk_val[iter] = val_dmk\n","\n","            # Actual value\n","            y_t1_actual = y[t-s:t+1][-1]\n","            weights = 1 / y_t1_actual.shape[0] * np.ones(y_t1_actual.shape[0])\n","            val_actual = np.dot(weights, y_t1_actual)\n","            true_val[iter] = val_actual\n","\n","            # Absolute error DMK\n","            abs_error_dmk[iter] = np.abs(val_actual - val_dmk)\n","\n","            print(f\"Iteration {iter}/{T-s}\")\n","            iter += 1\n","\n","    return abs_error_dmk, dmk_val, true_val"],"metadata":{"id":"zX5ktOdUtomC"},"execution_count":null,"outputs":[]}]}